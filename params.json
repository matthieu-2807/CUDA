{"name":"Cuda","tagline":"Fichiers sources pour le cours de CUDA","body":"### Bienvenue\r\n**Le rapport et les fichiers sources utilisés lors du cours de CUDA avec M.GABER sont disponibles en téléchargement dans les fichiers .ZIP et TAR.GZ ci-dessus.**\r\n\r\n\r\n### Lab 0 - CUDA Hello World !\r\nLe Lab 0 est la découverte de CUDA, nous commençons donc avec le fameux Hello World.\r\n\r\n``` c\r\n#include <stdlib.h>\r\n#include <stdio.h>\r\n\r\n__global__ void kernel(void){}\r\n\r\nint main()\r\n{\r\n    kernel<<<1,1>>>();\r\n    printf(\"Hello World !\\n);\r\n    return EXIT_SUCCESS;\r\n}\r\n```\r\n\r\n\r\n### Lab 1\r\nL'étape suivante est l'allocation de mémoire dans le GPU, l'échange de donnée entre le CPU et le GPU et l'exécution du code dans le GPU. Nous ajoutons à cela un timer et une gestion des erreurs lors des allocations de mémoire.\r\n\r\n``` c\r\n__global__  void vecAdd(float* A, float* B, float* C) \r\n{  \r\n    int i = blockIdx.x * blockDim.x + threadIdx.x; \r\n    C[i] = A[i] + B[i]; \r\n}\r\n\r\n#define cudaSafeCall(err) __cudaSafeCall(err, __FILE__, __LINE__)\r\nvoid __cudaSafeCall(cudaError_t err, char *file, int line) \r\n{\r\n    if ((err) != cudaSuccess)\r\n    {\r\n        fprintf(stderr, \"CUDA error in file %s at line %i: %s.\\n\", file, line, cudaGetErrorString(err));\r\n        exit(EXIT_FAILURE);\r\n    }\r\n}\r\n\r\nint  main(int argc, char **argv)\r\n{\r\n    int i, N = 720896;  /* default vector size */\r\n    float *A, *devPtrA;\r\n    \r\n// ...\r\n    \r\n    /* allocate host memory */\r\n    A = (float*)malloc(N * sizeof(float));\r\n    /* ----- GPU add-on ------- */\r\n    cudaSafeCall( cudaMalloc((void**)&devPtrA, N * sizeof(float)) ); \r\n    cudaSafeCall( cudaMemcpy(devPtrA, A, N * sizeof(float), cudaMemcpyHostToDevice) );\r\n    \r\n//...\r\n\r\n    /* call compute kernel */\r\n    vecAdd<<<N/512, 512>>>(devPtrA, devPtrB, devPtrC);\r\n    \r\n    cudaSafeCall( cudaMemcpy(C, devPtrC, N * sizeof(float),  cudaMemcpyDeviceToHost) );\r\n    \r\n//...    \r\n    \r\n    cudaSafeCall( cudaFree(devPtrA) );\r\n    free(A);\r\n}\r\n```\r\n\r\n\r\n### Lab 2 : Device Management API\r\nCette partie consiste à s'assurer que le GPU est compatible avec le code que nous souhaitons exécuter. Ici nous utilisons un GPU qui a la version 2.1, mais notre code vérifie que le GPU soit équipé d'une version 1.3 ou plus.\r\nDe plus, nous séparons les codes C et CUDA dans des fichiers différents et réalisons un makefile permettant de compiler plusieurs fichier (.c et .cu) en une commande.\r\n\r\n\r\n### Lab 3 : Sum / Dot product\r\nIl s'agit ici de faire un produit scalaire en partant du code s'exécutant sur le CPU et en le rendant exécutable sur le GPU. Le produit scalaire (dot product) consiste à prendre des groupes de 2 nombres (entiers, décimaux, …) et de faire la somme des produits de ces 2 nombres.\r\n\r\nVoici le code utilisé par le GPU pour le produit scalaire :\r\n\r\n``` c\r\n__global__ void dot(int *A, int *B, int *S)\r\n{\r\n\t__shared__ float temp[THREADS_PER_BLOCK];\r\n\tint index = threadIdx.x + blockIdx.x * blockDim.x;\r\n\ttemp[threadIdx.x] = A[index] * B[index];\r\n\r\n\t__syncthreads();\r\n\r\n\tif (0 == threadIdx.x)\r\n\t{\r\n\t\tint sum = 0;\r\n\t\tfor (int i = 0; i < THREADS_PER_BLOCK; i++)\r\n\t\t\tsum += temp[i];\r\n\r\n\t\tatomicAdd(S, sum);\r\n\t}\r\n}\r\n```\r\n\r\n### Lab 4 : Matrix-Matrix multiplication\r\n\r\n### Auteurs\r\nLes étudiants ayant participés à ce projet sont M. David BOTTIAU et M. Matthieu LEFEVRE, étudiant en 4ème année à l'EPSI d'Arras.","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}